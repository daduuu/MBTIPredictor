{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/SSD3/dud/miniconda3/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/mnt/SSD3/dud/miniconda3/lib/python3.10/site-packages/transformers/models/t5/tokenization_t5_fast.py:156: FutureWarning: This tokenizer was incorrectly instantiated with a model max length of 512 which will be corrected in Transformers v5.\n",
      "For now, this behavior is kept to avoid breaking backwards compatibility when padding/encoding with `truncation is True`.\n",
      "- Be aware that you SHOULD NOT rely on t5-base automatically truncating your input to 512 when padding/encoding.\n",
      "- If you want to encode/pad to sequences longer than 512 you can either instantiate this tokenizer with `model_max_length` or pass `max_length` when encoding/padding.\n",
      "- To avoid this warning, please instantiate this tokenizer with `model_max_length` set to your preferred value.\n",
      "  warnings.warn(\n",
      "/mnt/SSD3/dud/miniconda3/lib/python3.10/site-packages/torch/cuda/__init__.py:146: UserWarning: \n",
      "NVIDIA RTX A5000 with CUDA capability sm_86 is not compatible with the current PyTorch installation.\n",
      "The current PyTorch install supports CUDA capabilities sm_37 sm_50 sm_60 sm_70.\n",
      "If you want to use the NVIDIA RTX A5000 GPU with PyTorch, please check the instructions at https://pytorch.org/get-started/locally/\n",
      "\n",
      "  warnings.warn(incompatible_device_warn.format(device_name, capability, \" \".join(arch_list), device_name))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from global_vars import *\n",
    "import torch\n",
    "from transformers import AutoModelWithLMHead, AutoTokenizer, T5ForConditionalGeneration\n",
    "from datasets import Dataset, load_from_disk\n",
    "from torch.utils.data import DataLoader, RandomSampler, BatchSampler\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import wandb\n",
    "import pickle\n",
    "import sys\n",
    "from datetime import datetime\n",
    "\n",
    "dict = {\n",
    "    \"model_name\": model_t5,\n",
    "    \"learning_rate\": learning_rate,\n",
    "    \"max_length_input\": max_length_input,\n",
    "    \"doTruncate\": doTruncate,\n",
    "    \"doPadding\": doPadding,\n",
    "    \"split_train_test\": split_train_test,\n",
    "    \"split_train_val\": split_train_val,\n",
    "    \"batch_size\": batch_size,\n",
    "    \"epochs\": epochs,\n",
    "    \"layers_freeze\": layers_freeze,\n",
    "}\n",
    "device = torch.device(\"cuda:3\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model_saved = \"t52023-03-18-13-13-00.pt\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_t5)\n",
    "model = T5ForConditionalGeneration.from_pretrained(model_t5).to(device)\n",
    "model.load_state_dict(torch.load(model_saved, map_location=torch.device('cpu')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_accuracy(preds, labels):\n",
    "    o2 = [tokenizer.decode(preds[i], skip_special_tokens=True) for i in range(preds.shape[0])]\n",
    "    b3 = [tokenizer.decode(labels[i], skip_special_tokens=True) for i in range(labels.shape[0])]\n",
    "    count = 0\n",
    "    for i in range(len(o2)):\n",
    "        if o2[i].lower().strip() == b3[i].lower().strip():\n",
    "            count += 1\n",
    "    return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "time = \"2023-03-18-04-46-28\"\n",
    "testing_dataset_input = load_from_disk(\"dataset\" + time + \"/testing_dataset_input\")\n",
    "testing_dataset_labels = load_from_disk(\"dataset\" + time + \"/testing_dataset_labels\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_dataset = Dataset.from_dict({\"input_ids\": testing_dataset_input['input_ids'], #train input ids\n",
    "                                \"attention_mask\": testing_dataset_input['attention_mask'],\n",
    "                             \"labels_input_ids\": testing_dataset_labels['input_ids'] #label input ids\n",
    "                             }).with_format(\"torch\")\n",
    "test_dataloader = DataLoader(testing_dataset, batch_size=batch_size, drop_last=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 663/663 [06:19<00:00,  1.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8108974358974359\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "val_acc = 0\n",
    "for batch in tqdm(test_dataloader):\n",
    "    output = model(input_ids=batch[\"input_ids\"].to(device),\n",
    "                    attention_mask=batch[\"attention_mask\"].to(device),\n",
    "                     labels=batch[\"labels_input_ids\"].to(device))\n",
    "    outs2 = model.generate(batch[\"input_ids\"].to(device), max_new_tokens=4).to(device)\n",
    "    val_acc += compute_accuracy(outs2, batch[\"labels_input_ids\"])\n",
    "\n",
    "print(val_acc / len(testing_dataset))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
