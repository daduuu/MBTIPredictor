{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from global_vars import *\n",
    "from transformers import AutoModelForMultipleChoice, AutoTokenizer\n",
    "from datasets import Dataset, load_from_disk\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import wandb\n",
    "import pickle\n",
    "import numpy as np\n",
    "from wandb.keras import WandbMetricsLogger, WandbCallback\n",
    "import tensorflow as tf\n",
    "import os\n",
    "from tensorflow.keras import Model # if only machine learning were this easy :P\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "#import any other libraries you want here:\n",
    "from tensorflow.keras.layers import Dense, SpatialDropout1D, LSTM, Embedding, GlobalAveragePooling1D\n",
    "from tensorflow.keras.activations import softmax\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.callbacks import EarlyStopping, LambdaCallback, ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    }
   ],
   "source": [
    "print(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33meihuang\u001b[0m (\u001b[33mmbtipredictor\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\enoch\\MBTIPredictor\\wandb\\run-20230318_204601-kwsqvxmx</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/mbtipredictor/mbti_bert_mlm/runs/kwsqvxmx' target=\"_blank\">spring-night-374</a></strong> to <a href='https://wandb.ai/mbtipredictor/mbti_bert_mlm' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/mbtipredictor/mbti_bert_mlm' target=\"_blank\">https://wandb.ai/mbtipredictor/mbti_bert_mlm</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/mbtipredictor/mbti_bert_mlm/runs/kwsqvxmx' target=\"_blank\">https://wandb.ai/mbtipredictor/mbti_bert_mlm/runs/kwsqvxmx</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "run = wandb.init(\n",
    "    project=\"mbti_bert_mlm\",\n",
    "    config=dict,\n",
    "    entity=\"mbtipredictor\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 106067 entries, 0 to 106066\n",
      "Data columns (total 4 columns):\n",
      " #   Column   Non-Null Count   Dtype \n",
      "---  ------   --------------   ----- \n",
      " 0   posts    106067 non-null  object\n",
      " 1   type     106067 non-null  object\n",
      " 2   new_col  106067 non-null  int64 \n",
      " 3   pad      106067 non-null  object\n",
      "dtypes: int64(1), object(3)\n",
      "memory usage: 3.2+ MB\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"converted_new_for_custom.csv\")\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 256681 unique tokens.\n"
     ]
    }
   ],
   "source": [
    "# The maximum number of words to be used. (most frequent)\n",
    "MAX_NB_WORDS = 50000\n",
    "# Max number of words in each complaint.\n",
    "MAX_SEQUENCE_LENGTH = 500\n",
    "# This is fixed.\n",
    "EMBEDDING_DIM = 100\n",
    "tokenizer = Tokenizer(num_words=MAX_NB_WORDS, filters='!\"#$%&()*+,-./:;<=>?@[\\]^_`{|}~', lower=True)\n",
    "tokenizer.fit_on_texts(df['posts'].values)\n",
    "word_index = tokenizer.word_index\n",
    "print('Found %s unique tokens.' % len(word_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of data tensor: (106067, 500)\n"
     ]
    }
   ],
   "source": [
    "X = tokenizer.texts_to_sequences(df['posts'].values)\n",
    "X = pad_sequences(X, maxlen=MAX_SEQUENCE_LENGTH)\n",
    "print('Shape of data tensor:', X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of label tensor: (106067, 16)\n"
     ]
    }
   ],
   "source": [
    "Y = pd.get_dummies(df['type']).values\n",
    "print('Shape of label tensor:', Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(95460, 500) (95460, 16)\n",
      "(10607, 500) (10607, 16)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X,Y, test_size = 0.10, random_state = 42)\n",
    "print(X_train.shape,Y_train.shape)\n",
    "print(X_test.shape,Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(85914, 500) (85914, 16)\n",
      "(9546, 500) (9546, 16)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_val, Y_train, Y_val = train_test_split(X_train,Y_train, test_size = 0.10, random_state = 42)\n",
    "print(X_train.shape,Y_train.shape)\n",
    "print(X_val.shape,Y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<function print>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xt= X_train[:100]\n",
    "xv = X_val[:10]\n",
    "xte = X_test[:10]\n",
    "yt= Y_train[:100]\n",
    "yv = Y_val[:10]\n",
    "yte = Y_test[:10]\n",
    "\n",
    "print(len(xt))\n",
    "print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 500, 100)          5000000   \n",
      "                                                                 \n",
      " spatial_dropout1d (SpatialD  (None, 500, 100)         0         \n",
      " ropout1D)                                                       \n",
      "                                                                 \n",
      " lstm_1 (LSTM)               (None, 500, 100)          80400     \n",
      "                                                                 \n",
      " lstm_2 (LSTM)               (None, 500, 50)           30200     \n",
      "                                                                 \n",
      " globalaveragepooling1d (Glo  (None, 50)               0         \n",
      " balAveragePooling1D)                                            \n",
      "                                                                 \n",
      " dense (Dense)               (None, 16)                816       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 5,111,416\n",
      "Trainable params: 5,111,416\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(MAX_NB_WORDS, EMBEDDING_DIM, input_length=X.shape[1]))\n",
    "model.add(SpatialDropout1D(0.2))\n",
    "model.add(LSTM(100, dropout=0.2, recurrent_dropout=0.2, name = \"lstm_1\", return_sequences=True))\n",
    "model.add(LSTM(50, dropout=0.1, recurrent_dropout=0.1, name = \"lstm_2\", return_sequences=True))\n",
    "model.add(GlobalAveragePooling1D(name = \"globalaveragepooling1d\"))\n",
    "model.add(Dense(16, activation='softmax', name = \"dense\"))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21479\n",
      "2387\n"
     ]
    }
   ],
   "source": [
    "# Prepare the training dataset.\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((X_train, Y_train))\n",
    "train_dataset = train_dataset.shuffle(buffer_size=1024).batch(batch_size)\n",
    "\n",
    "# Prepare the validation dataset.\n",
    "val_dataset = tf.data.Dataset.from_tensor_slices((X_val, Y_val))\n",
    "val_dataset = val_dataset.batch(batch_size)\n",
    "\n",
    "print(len(train_dataset))\n",
    "print(len(val_dataset))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start\n",
      "\n",
      "Start of epoch 0\n",
      "Training loss (for one batch) at step 0: 2.7734\n",
      "Seen so far: 4 samples\n",
      "Validation loss (for 200 batch) at step 0: 2.7690\n",
      "Training loss (for one batch) at step 1: 2.7700\n",
      "Seen so far: 8 samples\n",
      "Training loss (for one batch) at step 2: 2.7705\n",
      "Seen so far: 12 samples\n",
      "Training loss (for one batch) at step 3: 2.7509\n",
      "Seen so far: 16 samples\n",
      "Training loss (for one batch) at step 4: 2.7528\n",
      "Seen so far: 20 samples\n",
      "Training loss (for one batch) at step 5: 2.7388\n",
      "Seen so far: 24 samples\n",
      "Training loss (for one batch) at step 6: 2.7180\n",
      "Seen so far: 28 samples\n",
      "Training loss (for one batch) at step 7: 2.7297\n",
      "Seen so far: 32 samples\n",
      "Training loss (for one batch) at step 8: 2.6718\n",
      "Seen so far: 36 samples\n",
      "Training loss (for one batch) at step 9: 2.6513\n",
      "Seen so far: 40 samples\n",
      "Training loss (for one batch) at step 10: 2.6603\n",
      "Seen so far: 44 samples\n",
      "Training loss (for one batch) at step 11: 2.5126\n",
      "Seen so far: 48 samples\n",
      "Training loss (for one batch) at step 12: 2.4865\n",
      "Seen so far: 52 samples\n",
      "Training loss (for one batch) at step 13: 2.3666\n",
      "Seen so far: 56 samples\n",
      "Training loss (for one batch) at step 14: 1.6303\n",
      "Seen so far: 60 samples\n",
      "Training loss (for one batch) at step 15: 2.7740\n",
      "Seen so far: 64 samples\n",
      "Training loss (for one batch) at step 16: 2.2848\n",
      "Seen so far: 68 samples\n",
      "Training loss (for one batch) at step 17: 2.8174\n",
      "Seen so far: 72 samples\n",
      "Training loss (for one batch) at step 18: 2.6486\n",
      "Seen so far: 76 samples\n",
      "Training loss (for one batch) at step 19: 2.3759\n",
      "Seen so far: 80 samples\n",
      "Training loss (for one batch) at step 20: 1.7568\n",
      "Seen so far: 84 samples\n",
      "Training loss (for one batch) at step 21: 2.8542\n",
      "Seen so far: 88 samples\n",
      "Training loss (for one batch) at step 22: 1.8975\n",
      "Seen so far: 92 samples\n",
      "Training loss (for one batch) at step 23: 2.8502\n",
      "Seen so far: 96 samples\n",
      "Training loss (for one batch) at step 24: 2.4092\n",
      "Seen so far: 100 samples\n",
      "Training loss (for one batch) at step 25: 1.4966\n",
      "Seen so far: 104 samples\n",
      "Training loss (for one batch) at step 26: 2.0617\n",
      "Seen so far: 108 samples\n",
      "Training loss (for one batch) at step 27: 1.6709\n",
      "Seen so far: 112 samples\n",
      "Training loss (for one batch) at step 28: 2.4944\n",
      "Seen so far: 116 samples\n",
      "Training loss (for one batch) at step 29: 2.3642\n",
      "Seen so far: 120 samples\n",
      "Training loss (for one batch) at step 30: 1.8813\n",
      "Seen so far: 124 samples\n",
      "Training loss (for one batch) at step 31: 2.4163\n",
      "Seen so far: 128 samples\n",
      "Training loss (for one batch) at step 32: 2.0761\n",
      "Seen so far: 132 samples\n",
      "Training loss (for one batch) at step 33: 2.7894\n",
      "Seen so far: 136 samples\n",
      "Training loss (for one batch) at step 34: 2.3829\n",
      "Seen so far: 140 samples\n",
      "Training loss (for one batch) at step 35: 2.2139\n",
      "Seen so far: 144 samples\n",
      "Training loss (for one batch) at step 36: 2.5951\n",
      "Seen so far: 148 samples\n",
      "Training loss (for one batch) at step 37: 1.7009\n",
      "Seen so far: 152 samples\n",
      "Training loss (for one batch) at step 38: 2.0004\n",
      "Seen so far: 156 samples\n",
      "Training loss (for one batch) at step 39: 1.9119\n",
      "Seen so far: 160 samples\n",
      "Training loss (for one batch) at step 40: 1.7331\n",
      "Seen so far: 164 samples\n",
      "Training loss (for one batch) at step 41: 2.0596\n",
      "Seen so far: 168 samples\n",
      "Training loss (for one batch) at step 42: 2.1209\n",
      "Seen so far: 172 samples\n",
      "Training loss (for one batch) at step 43: 2.1116\n",
      "Seen so far: 176 samples\n",
      "Training loss (for one batch) at step 44: 2.5322\n",
      "Seen so far: 180 samples\n",
      "Training loss (for one batch) at step 45: 1.9495\n",
      "Seen so far: 184 samples\n",
      "Training loss (for one batch) at step 46: 2.3485\n",
      "Seen so far: 188 samples\n",
      "Training loss (for one batch) at step 47: 1.6160\n",
      "Seen so far: 192 samples\n",
      "Training loss (for one batch) at step 48: 2.0917\n",
      "Seen so far: 196 samples\n",
      "Training loss (for one batch) at step 49: 2.7537\n",
      "Seen so far: 200 samples\n",
      "Training loss (for one batch) at step 50: 2.1303\n",
      "Seen so far: 204 samples\n",
      "Training loss (for one batch) at step 51: 2.9392\n",
      "Seen so far: 208 samples\n",
      "Training loss (for one batch) at step 52: 2.1841\n",
      "Seen so far: 212 samples\n",
      "Training loss (for one batch) at step 53: 2.6145\n",
      "Seen so far: 216 samples\n",
      "Training loss (for one batch) at step 54: 2.4958\n",
      "Seen so far: 220 samples\n",
      "Training loss (for one batch) at step 55: 1.7828\n",
      "Seen so far: 224 samples\n",
      "Training loss (for one batch) at step 56: 2.4894\n",
      "Seen so far: 228 samples\n",
      "Training loss (for one batch) at step 57: 1.9577\n",
      "Seen so far: 232 samples\n",
      "Training loss (for one batch) at step 58: 2.3427\n",
      "Seen so far: 236 samples\n",
      "Training loss (for one batch) at step 59: 1.9390\n",
      "Seen so far: 240 samples\n",
      "Training loss (for one batch) at step 60: 2.1817\n",
      "Seen so far: 244 samples\n",
      "Training loss (for one batch) at step 61: 2.2614\n",
      "Seen so far: 248 samples\n",
      "Training loss (for one batch) at step 62: 1.8371\n",
      "Seen so far: 252 samples\n",
      "Training loss (for one batch) at step 63: 1.6702\n",
      "Seen so far: 256 samples\n",
      "Training loss (for one batch) at step 64: 1.6679\n",
      "Seen so far: 260 samples\n",
      "Training loss (for one batch) at step 65: 1.6444\n",
      "Seen so far: 264 samples\n",
      "Training loss (for one batch) at step 66: 2.0501\n",
      "Seen so far: 268 samples\n",
      "Training loss (for one batch) at step 67: 2.1275\n",
      "Seen so far: 272 samples\n",
      "Training loss (for one batch) at step 68: 2.4748\n",
      "Seen so far: 276 samples\n",
      "Training loss (for one batch) at step 69: 1.7803\n",
      "Seen so far: 280 samples\n",
      "Training loss (for one batch) at step 70: 1.6714\n",
      "Seen so far: 284 samples\n",
      "Training loss (for one batch) at step 71: 2.7239\n",
      "Seen so far: 288 samples\n",
      "Training loss (for one batch) at step 72: 2.3263\n",
      "Seen so far: 292 samples\n",
      "Training loss (for one batch) at step 73: 1.7937\n",
      "Seen so far: 296 samples\n",
      "Training loss (for one batch) at step 74: 1.9512\n",
      "Seen so far: 300 samples\n",
      "Training loss (for one batch) at step 75: 1.9785\n",
      "Seen so far: 304 samples\n",
      "Training loss (for one batch) at step 76: 1.8272\n",
      "Seen so far: 308 samples\n",
      "Training loss (for one batch) at step 77: 1.7887\n",
      "Seen so far: 312 samples\n",
      "Training loss (for one batch) at step 78: 2.7934\n",
      "Seen so far: 316 samples\n",
      "Training loss (for one batch) at step 79: 2.4345\n",
      "Seen so far: 320 samples\n",
      "Training loss (for one batch) at step 80: 2.3306\n",
      "Seen so far: 324 samples\n",
      "Training loss (for one batch) at step 81: 1.7183\n",
      "Seen so far: 328 samples\n",
      "Training loss (for one batch) at step 82: 2.4230\n",
      "Seen so far: 332 samples\n",
      "Training loss (for one batch) at step 83: 1.6697\n",
      "Seen so far: 336 samples\n",
      "Training loss (for one batch) at step 84: 1.9155\n",
      "Seen so far: 340 samples\n",
      "Training loss (for one batch) at step 85: 2.2917\n",
      "Seen so far: 344 samples\n",
      "Training loss (for one batch) at step 86: 1.7495\n",
      "Seen so far: 348 samples\n",
      "Training loss (for one batch) at step 87: 2.2443\n",
      "Seen so far: 352 samples\n",
      "Training loss (for one batch) at step 88: 2.4086\n",
      "Seen so far: 356 samples\n",
      "Training loss (for one batch) at step 89: 1.7223\n",
      "Seen so far: 360 samples\n",
      "Training loss (for one batch) at step 90: 2.6794\n",
      "Seen so far: 364 samples\n",
      "Training loss (for one batch) at step 91: 1.7851\n",
      "Seen so far: 368 samples\n",
      "Training loss (for one batch) at step 92: 2.0880\n",
      "Seen so far: 372 samples\n",
      "Training loss (for one batch) at step 93: 2.5827\n",
      "Seen so far: 376 samples\n",
      "Training loss (for one batch) at step 94: 1.7678\n",
      "Seen so far: 380 samples\n",
      "Training loss (for one batch) at step 95: 2.2351\n",
      "Seen so far: 384 samples\n",
      "Training loss (for one batch) at step 96: 1.6169\n",
      "Seen so far: 388 samples\n",
      "Training loss (for one batch) at step 97: 2.4737\n",
      "Seen so far: 392 samples\n",
      "Training loss (for one batch) at step 98: 1.7294\n",
      "Seen so far: 396 samples\n",
      "Training loss (for one batch) at step 99: 1.6607\n",
      "Seen so far: 400 samples\n",
      "Training loss (for one batch) at step 100: 2.8172\n",
      "Seen so far: 404 samples\n",
      "Training loss (for one batch) at step 101: 1.9629\n",
      "Seen so far: 408 samples\n",
      "Training loss (for one batch) at step 102: 2.0967\n",
      "Seen so far: 412 samples\n",
      "Training loss (for one batch) at step 103: 1.9919\n",
      "Seen so far: 416 samples\n",
      "Training loss (for one batch) at step 104: 1.6420\n",
      "Seen so far: 420 samples\n",
      "Training loss (for one batch) at step 105: 2.4127\n",
      "Seen so far: 424 samples\n",
      "Training loss (for one batch) at step 106: 2.7438\n",
      "Seen so far: 428 samples\n",
      "Training loss (for one batch) at step 107: 2.0595\n",
      "Seen so far: 432 samples\n",
      "Training loss (for one batch) at step 108: 2.8021\n",
      "Seen so far: 436 samples\n",
      "Training loss (for one batch) at step 109: 1.9107\n",
      "Seen so far: 440 samples\n",
      "Training loss (for one batch) at step 110: 2.7376\n",
      "Seen so far: 444 samples\n",
      "Training loss (for one batch) at step 111: 2.1346\n",
      "Seen so far: 448 samples\n",
      "Training loss (for one batch) at step 112: 1.6297\n",
      "Seen so far: 452 samples\n",
      "Training loss (for one batch) at step 113: 2.1795\n",
      "Seen so far: 456 samples\n",
      "Training loss (for one batch) at step 114: 2.9909\n",
      "Seen so far: 460 samples\n",
      "Training loss (for one batch) at step 115: 2.1760\n",
      "Seen so far: 464 samples\n",
      "Training loss (for one batch) at step 116: 1.9374\n",
      "Seen so far: 468 samples\n",
      "Training loss (for one batch) at step 117: 1.9262\n",
      "Seen so far: 472 samples\n",
      "Training loss (for one batch) at step 118: 2.7286\n",
      "Seen so far: 476 samples\n",
      "Training loss (for one batch) at step 119: 2.1412\n",
      "Seen so far: 480 samples\n",
      "Training loss (for one batch) at step 120: 1.9447\n",
      "Seen so far: 484 samples\n",
      "Training loss (for one batch) at step 121: 2.3535\n",
      "Seen so far: 488 samples\n",
      "Training loss (for one batch) at step 122: 2.3064\n",
      "Seen so far: 492 samples\n",
      "Training loss (for one batch) at step 123: 2.4162\n",
      "Seen so far: 496 samples\n",
      "Training loss (for one batch) at step 124: 2.1355\n",
      "Seen so far: 500 samples\n",
      "Training loss (for one batch) at step 125: 1.7683\n",
      "Seen so far: 504 samples\n",
      "Training loss (for one batch) at step 126: 2.9658\n",
      "Seen so far: 508 samples\n",
      "Training loss (for one batch) at step 127: 1.9889\n",
      "Seen so far: 512 samples\n",
      "Training loss (for one batch) at step 128: 1.6944\n",
      "Seen so far: 516 samples\n",
      "Training loss (for one batch) at step 129: 1.8852\n",
      "Seen so far: 520 samples\n",
      "Training loss (for one batch) at step 130: 2.3646\n",
      "Seen so far: 524 samples\n",
      "Training loss (for one batch) at step 131: 2.1778\n",
      "Seen so far: 528 samples\n",
      "Training loss (for one batch) at step 132: 1.7307\n",
      "Seen so far: 532 samples\n",
      "Training loss (for one batch) at step 133: 2.9504\n",
      "Seen so far: 536 samples\n",
      "Training loss (for one batch) at step 134: 2.0546\n",
      "Seen so far: 540 samples\n",
      "Training loss (for one batch) at step 135: 1.7233\n",
      "Seen so far: 544 samples\n",
      "Training loss (for one batch) at step 136: 1.8558\n",
      "Seen so far: 548 samples\n",
      "Training loss (for one batch) at step 137: 1.6847\n",
      "Seen so far: 552 samples\n",
      "Training loss (for one batch) at step 138: 2.0808\n",
      "Seen so far: 556 samples\n",
      "Training loss (for one batch) at step 139: 1.7705\n",
      "Seen so far: 560 samples\n",
      "Training loss (for one batch) at step 140: 2.4670\n",
      "Seen so far: 564 samples\n",
      "Training loss (for one batch) at step 141: 2.2376\n",
      "Seen so far: 568 samples\n",
      "Training loss (for one batch) at step 142: 2.6398\n",
      "Seen so far: 572 samples\n",
      "Training loss (for one batch) at step 143: 3.2336\n",
      "Seen so far: 576 samples\n",
      "Training loss (for one batch) at step 144: 3.7150\n",
      "Seen so far: 580 samples\n",
      "Training loss (for one batch) at step 145: 1.9179\n",
      "Seen so far: 584 samples\n",
      "Training loss (for one batch) at step 146: 2.4529\n",
      "Seen so far: 588 samples\n",
      "Training loss (for one batch) at step 147: 1.8997\n",
      "Seen so far: 592 samples\n",
      "Training loss (for one batch) at step 148: 1.6231\n",
      "Seen so far: 596 samples\n",
      "Training loss (for one batch) at step 149: 1.8800\n",
      "Seen so far: 600 samples\n",
      "Training loss (for one batch) at step 150: 3.0147\n",
      "Seen so far: 604 samples\n",
      "Training loss (for one batch) at step 151: 2.7117\n",
      "Seen so far: 608 samples\n",
      "Training loss (for one batch) at step 152: 2.0653\n",
      "Seen so far: 612 samples\n",
      "Training loss (for one batch) at step 153: 2.2047\n",
      "Seen so far: 616 samples\n",
      "Training loss (for one batch) at step 154: 2.1872\n",
      "Seen so far: 620 samples\n",
      "Training loss (for one batch) at step 155: 2.0293\n",
      "Seen so far: 624 samples\n",
      "Training loss (for one batch) at step 156: 1.7642\n",
      "Seen so far: 628 samples\n",
      "Training loss (for one batch) at step 157: 1.7956\n",
      "Seen so far: 632 samples\n",
      "Training loss (for one batch) at step 158: 1.7137\n",
      "Seen so far: 636 samples\n",
      "Training loss (for one batch) at step 159: 1.7332\n",
      "Seen so far: 640 samples\n",
      "Training loss (for one batch) at step 160: 2.7529\n",
      "Seen so far: 644 samples\n",
      "Training loss (for one batch) at step 161: 1.8285\n",
      "Seen so far: 648 samples\n",
      "Training loss (for one batch) at step 162: 1.9393\n",
      "Seen so far: 652 samples\n",
      "Training loss (for one batch) at step 163: 2.3710\n",
      "Seen so far: 656 samples\n",
      "Training loss (for one batch) at step 164: 2.2818\n",
      "Seen so far: 660 samples\n",
      "Training loss (for one batch) at step 165: 2.2172\n",
      "Seen so far: 664 samples\n",
      "Training loss (for one batch) at step 166: 2.3867\n",
      "Seen so far: 668 samples\n",
      "Training loss (for one batch) at step 167: 2.0273\n",
      "Seen so far: 672 samples\n",
      "Training loss (for one batch) at step 168: 2.3898\n",
      "Seen so far: 676 samples\n",
      "Training loss (for one batch) at step 169: 1.8110\n",
      "Seen so far: 680 samples\n",
      "Training loss (for one batch) at step 170: 2.9140\n",
      "Seen so far: 684 samples\n",
      "Training loss (for one batch) at step 171: 1.9472\n",
      "Seen so far: 688 samples\n",
      "Training loss (for one batch) at step 172: 2.5512\n",
      "Seen so far: 692 samples\n",
      "Training loss (for one batch) at step 173: 2.2786\n",
      "Seen so far: 696 samples\n",
      "Training loss (for one batch) at step 174: 1.7724\n",
      "Seen so far: 700 samples\n",
      "Training loss (for one batch) at step 175: 3.0128\n",
      "Seen so far: 704 samples\n",
      "Training loss (for one batch) at step 176: 1.5862\n",
      "Seen so far: 708 samples\n",
      "Training loss (for one batch) at step 177: 2.7266\n",
      "Seen so far: 712 samples\n",
      "Training loss (for one batch) at step 178: 2.1399\n",
      "Seen so far: 716 samples\n",
      "Training loss (for one batch) at step 179: 2.5103\n",
      "Seen so far: 720 samples\n",
      "Training loss (for one batch) at step 180: 1.9424\n",
      "Seen so far: 724 samples\n",
      "Training loss (for one batch) at step 181: 2.4136\n",
      "Seen so far: 728 samples\n",
      "Training loss (for one batch) at step 182: 2.2006\n",
      "Seen so far: 732 samples\n",
      "Training loss (for one batch) at step 183: 2.4203\n",
      "Seen so far: 736 samples\n",
      "Training loss (for one batch) at step 184: 2.9120\n",
      "Seen so far: 740 samples\n",
      "Training loss (for one batch) at step 185: 2.7269\n",
      "Seen so far: 744 samples\n",
      "Training loss (for one batch) at step 186: 2.7402\n",
      "Seen so far: 748 samples\n",
      "Training loss (for one batch) at step 187: 2.1718\n",
      "Seen so far: 752 samples\n",
      "Training loss (for one batch) at step 188: 2.0358\n",
      "Seen so far: 756 samples\n",
      "Training loss (for one batch) at step 189: 1.4411\n",
      "Seen so far: 760 samples\n",
      "Training loss (for one batch) at step 190: 2.2619\n",
      "Seen so far: 764 samples\n",
      "Training loss (for one batch) at step 191: 2.2868\n",
      "Seen so far: 768 samples\n",
      "Training loss (for one batch) at step 192: 1.6961\n",
      "Seen so far: 772 samples\n",
      "Training loss (for one batch) at step 193: 2.5091\n",
      "Seen so far: 776 samples\n",
      "Training loss (for one batch) at step 194: 2.3308\n",
      "Seen so far: 780 samples\n",
      "Training loss (for one batch) at step 195: 2.4528\n",
      "Seen so far: 784 samples\n",
      "Training loss (for one batch) at step 196: 2.4056\n",
      "Seen so far: 788 samples\n",
      "Training loss (for one batch) at step 197: 2.0771\n",
      "Seen so far: 792 samples\n",
      "Training loss (for one batch) at step 198: 2.2587\n",
      "Seen so far: 796 samples\n",
      "Training loss (for one batch) at step 199: 2.3421\n",
      "Seen so far: 800 samples\n",
      "Training loss (for one batch) at step 200: 2.0312\n",
      "Seen so far: 804 samples\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\enoch\\MBTIPredictor\\custom_model.ipynb Cell 13\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/enoch/MBTIPredictor/custom_model.ipynb#X15sZmlsZQ%3D%3D?line=43'>44</a>\u001b[0m \u001b[39mif\u001b[39;00m step \u001b[39m%\u001b[39m \u001b[39m200\u001b[39m \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/enoch/MBTIPredictor/custom_model.ipynb#X15sZmlsZQ%3D%3D?line=44'>45</a>\u001b[0m     \u001b[39mfor\u001b[39;00m x_batch_val, y_batch_val \u001b[39min\u001b[39;00m val_dataset:\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/enoch/MBTIPredictor/custom_model.ipynb#X15sZmlsZQ%3D%3D?line=45'>46</a>\u001b[0m         val_loss \u001b[39m=\u001b[39m test_step(x_batch_val, y_batch_val)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/enoch/MBTIPredictor/custom_model.ipynb#X15sZmlsZQ%3D%3D?line=46'>47</a>\u001b[0m     val_acc \u001b[39m=\u001b[39m val_acc_metric\u001b[39m.\u001b[39mresult()\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/enoch/MBTIPredictor/custom_model.ipynb#X15sZmlsZQ%3D%3D?line=47'>48</a>\u001b[0m     \u001b[39m#val_acc_metric.reset_states()\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:880\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    877\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    879\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 880\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[0;32m    882\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    883\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:919\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    916\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[0;32m    917\u001b[0m \u001b[39m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[0;32m    918\u001b[0m \u001b[39m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[1;32m--> 919\u001b[0m results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_variable_creation_fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[0;32m    920\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_created_variables \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m ALLOW_DYNAMIC_VARIABLE_CREATION:\n\u001b[0;32m    921\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mCreating variables on a non-first call to a function\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    922\u001b[0m                    \u001b[39m\"\u001b[39m\u001b[39m decorated with tf.function.\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compiler.py:134\u001b[0m, in \u001b[0;36mTracingCompiler.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    131\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[0;32m    132\u001b[0m   (concrete_function,\n\u001b[0;32m    133\u001b[0m    filtered_flat_args) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m--> 134\u001b[0m \u001b[39mreturn\u001b[39;00m concrete_function\u001b[39m.\u001b[39;49m_call_flat(\n\u001b[0;32m    135\u001b[0m     filtered_flat_args, captured_inputs\u001b[39m=\u001b[39;49mconcrete_function\u001b[39m.\u001b[39;49mcaptured_inputs)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\monomorphic_function.py:1745\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1741\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1742\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1743\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1744\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1745\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_call_outputs(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inference_function\u001b[39m.\u001b[39;49mcall(\n\u001b[0;32m   1746\u001b[0m       ctx, args, cancellation_manager\u001b[39m=\u001b[39;49mcancellation_manager))\n\u001b[0;32m   1747\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1748\u001b[0m     args,\n\u001b[0;32m   1749\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1750\u001b[0m     executing_eagerly)\n\u001b[0;32m   1751\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\monomorphic_function.py:378\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    376\u001b[0m \u001b[39mwith\u001b[39;00m _InterpolateFunctionError(\u001b[39mself\u001b[39m):\n\u001b[0;32m    377\u001b[0m   \u001b[39mif\u001b[39;00m cancellation_manager \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 378\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mexecute(\n\u001b[0;32m    379\u001b[0m         \u001b[39mstr\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msignature\u001b[39m.\u001b[39;49mname),\n\u001b[0;32m    380\u001b[0m         num_outputs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_num_outputs,\n\u001b[0;32m    381\u001b[0m         inputs\u001b[39m=\u001b[39;49margs,\n\u001b[0;32m    382\u001b[0m         attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[0;32m    383\u001b[0m         ctx\u001b[39m=\u001b[39;49mctx)\n\u001b[0;32m    384\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    385\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m    386\u001b[0m         \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msignature\u001b[39m.\u001b[39mname),\n\u001b[0;32m    387\u001b[0m         num_outputs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    390\u001b[0m         ctx\u001b[39m=\u001b[39mctx,\n\u001b[0;32m    391\u001b[0m         cancellation_manager\u001b[39m=\u001b[39mcancellation_manager)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\tensorflow\\python\\eager\\execute.py:52\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     51\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 52\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[0;32m     53\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     54\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     55\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "loss_fn = tf.keras.losses.CategoricalCrossentropy()\n",
    "optimizer = tf.keras.optimizers.Adam()\n",
    "train_acc_metric = tf.keras.metrics.CategoricalAccuracy()\n",
    "val_acc_metric = tf.keras.metrics.CategoricalAccuracy()\n",
    "\n",
    "@tf.function\n",
    "def train_step(x, y):\n",
    "    with tf.GradientTape() as tape:\n",
    "        logits = model(x, training=True)\n",
    "        loss_value = loss_fn(y, logits)\n",
    "    grads = tape.gradient(loss_value, model.trainable_weights)\n",
    "    optimizer.apply_gradients(zip(grads, model.trainable_weights))\n",
    "    train_acc_metric.update_state(y, logits)\n",
    "    return loss_value\n",
    "\n",
    "@tf.function\n",
    "def test_step(x, y):\n",
    "    val_logits = model(x, training=False)\n",
    "    val_loss_value = loss_fn(y, val_logits)\n",
    "    val_acc_metric.update_state(y, val_logits)\n",
    "    return val_loss_value\n",
    "\n",
    "\n",
    "print(\"start\")\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    print(\"\\nStart of epoch %d\" % (epoch,))\n",
    "\n",
    "    # Iterate over the batches of the dataset.\n",
    "    for step, (x_batch_train, y_batch_train) in enumerate(train_dataset):\n",
    "        loss_value = train_step(x_batch_train, y_batch_train)\n",
    "\n",
    "        # Log every 1 batches.\n",
    "        if step % 1 == 0:\n",
    "            train_acc = train_acc_metric.result()\n",
    "            #train_acc_metric.reset_states()\n",
    "            print(\n",
    "                \"Training loss (for one batch) at step %d: %.4f\"\n",
    "                % (step, float(loss_value))\n",
    "            )\n",
    "            print(\"Seen so far: %d samples\" % ((step + 1) * batch_size))\n",
    "            wandb.log({\"Training Loss\": loss_value, \"Train Acc\": train_acc})\n",
    "        # Run a validation loop each 200 steps\n",
    "        if step % 200 == 0:\n",
    "            for x_batch_val, y_batch_val in val_dataset:\n",
    "                val_loss = test_step(x_batch_val, y_batch_val)\n",
    "            val_acc = val_acc_metric.result()\n",
    "            #val_acc_metric.reset_states()\n",
    "            print(\n",
    "                \"Validation loss (for 200 batch) at step %d: %.4f\"\n",
    "                % (step, float(val_loss))\n",
    "            )\n",
    "            wandb.log({\"Validation Loss\": val_loss, \"Validation Acc\": val_acc})\n",
    "    # Display metrics at the end of each epoch.\n",
    "    train_acc = train_acc_metric.result()\n",
    "    print(\"Training acc over epoch: %.4f\" % (float(train_acc),))\n",
    "    wandb.log({\"Train Acc Epoch\": train_acc})\n",
    "    # Reset training metrics at the end of each epoch\n",
    "    train_acc_metric.reset_states()\n",
    "\n",
    "    # Run a validation loop at the end of each epoch.\n",
    "    for x_batch_val, y_batch_val in val_dataset:\n",
    "        test_step(x_batch_val, y_batch_val)\n",
    "\n",
    "    val_acc = val_acc_metric.result()\n",
    "    val_acc_metric.reset_states()\n",
    "    print(\"Validation acc: %.4f\" % (float(val_acc),))\n",
    "    wandb.log({\"Validation Acc Epoch\": val_acc})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 1s 137ms/step - loss: 1.9761 - categorical_accuracy: 0.1800\n",
      "Test set\n",
      "  Loss: 1.976\n",
      "  Accuracy: 0.180\n"
     ]
    }
   ],
   "source": [
    "accr = model.evaluate(X_test,Y_test)\n",
    "print('Test set\\n  Loss: {:0.3f}\\n  Accuracy: {:0.3f}'.format(accr[0],accr[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A subdirectory or file -p already exists.\n",
      "Error occurred while processing: -p.\n",
      "A subdirectory or file saved_model already exists.\n",
      "Error occurred while processing: saved_model.\n",
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: saved_model/my_model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: saved_model/my_model\\assets\n"
     ]
    }
   ],
   "source": [
    "!mkdir -p saved_model\n",
    "model.save('saved_model/my_model')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d99244a9e733483bb81d899488e5341e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Train Acc</td><td>▁▇█▅▅▆▆▆▆▇▇▆▆▇▇▇▆▆▇▆▆▆▆▆▆▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅</td></tr><tr><td>Training Loss</td><td>▆▆▅▆▆▁▅▄▃▃▇▂▄▄▆▂▂▄▂▅▃▃▄▃▄▃▇▂█▃▄▂▅▃▄▆▅▄▅▄</td></tr><tr><td>Validation Acc</td><td>▁</td></tr><tr><td>Validation Loss</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Train Acc</td><td>1e-05</td></tr><tr><td>Training Loss</td><td>2.03123</td></tr><tr><td>Validation Acc</td><td>8e-05</td></tr><tr><td>Validation Loss</td><td>0.00116</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">spring-night-374</strong> at: <a href='https://wandb.ai/mbtipredictor/mbti_bert_mlm/runs/kwsqvxmx' target=\"_blank\">https://wandb.ai/mbtipredictor/mbti_bert_mlm/runs/kwsqvxmx</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20230318_204601-kwsqvxmx\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "run.finish()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
